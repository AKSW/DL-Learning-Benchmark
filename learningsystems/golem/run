#!/usr/bin/env python

import argparse

try:
    import configparser
except ImportError:
    import ConfigParser as configparser

import logging
import os
import subprocess
import platform
import sys
import atexit
import signal
import ctypes
libc = ctypes.CDLL("libc.so.6")


def set_pdeathsig(sig = signal.SIGTERM):
    def callable():
        return libc.prctl(1, sig)
    return callable

procs = []

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s')
_log = logging.getLogger()


@atexit.register
def kill_subprocesses(*args, **kwargs):
    for proc in procs:
        if proc.returncode == None:
            _log.debug('killing %s at exit', proc)
        try:
            proc.kill()
            proc.terminate()
        except:
            pass

def sig_term(*args, **kwargs):
#    kill_subprocesses()
    sys.exit(signal.SIGTERM | 0x80)

signal.signal(signal.SIGTERM, sig_term)

def check_call_and_terminate(*args, **kwargs):
    pp = subprocess.Popen(*args, **kwargs)
    procs.append(pp)
    retcode = pp.wait()
    if retcode:
        raise subprocess.CalledProcessError(retcode, args[0])
    return retcode

learning_task_dir_name = 'learningtasks'
prolog_dir_name = 'prolog'
data_dir_name = 'data'
tool_specific_data_dir = 'golem'
lp_dir_name = 'lp'
settings_pattern = '!- set(%s,%s).'
config_file_name = 'golem.conf'
output_file_name = 'results.txt'
exec_file_name = 'golem'


def find_golem():
    gen_path = os.path.join(os.getcwd(),
                            '%s-%s' % (platform.system(), platform.machine()),
                            exec_file_name)
    direct_path = os.path.join(os.getcwd(), exec_file_name)

    if os.path.isfile(gen_path):
        # e.g. golem executable resides in the directory ./Linux-x86_64
        return gen_path

    elif os.path.isfile(direct_path):
        # golem executable resides in the same directory
        return direct_path

    else:
        # golem executable resides somewhere else; it is assumed that it can be
        # found somewhere in the system path
        return exec_file_name


def get_settings(learning_task, lp_id, cfg):
    config_file_path = os.path.join('..', '..', learning_task_dir_name,
                                    learning_task, prolog_dir_name,
                                    lp_dir_name, lp_id, config_file_name)

    settings = {}
    
    if os.path.isfile(config_file_path):

        conf = configparser.ConfigParser()
        conf.read(config_file_path)

        for item in conf.items('main'):
            setting, raw_value = item
            settings[setting] = raw_value

    for k, v in cfg.items():
        if k.startswith('settings'):
            # 'settings.caching' --> 'caching'
            k = k.split('.', 1)[1]
            settings[k] = v

    return settings


def read_config(path):
    conf = configparser.ConfigParser()
    conf.read(path)

    settings = {}
    for item in conf.items('main'):
        setting, raw_value = item
        settings[setting] = raw_value

    for item in conf.items('filename'):
        setting, raw_value = item
        settings['filename.'+setting] = raw_value

    if conf.has_section('settings'):
        for item in conf.items('settings'):
            setting, raw_value = item
            settings['settings.'+setting] = raw_value

    return settings


def copy_files_around(task_id, lp_id, target_dir, file_name_base, file_pos,
                      file_neg):
    """Finds all the files necessary to run golem:
    - ../../../learningtasks/<task_id>/prolog/data/golem/*.pl  # merged!
                             --> <target_dir>/<file_name_base>.b
    - ../../../learningtasks/<task_id>/prolog/data/*.pl  # merged!
                             --> <target_dir>/<file_name_base>.b
    - file_pos               --> <target_dir>/<file_name_base>.f
    - file_neg               --> <target_dir>/<file_name_base>.n
    """
    # <file_name_base>.b (background knowledge)
    data_dir = os.path.join('..', '..', learning_task_dir_name, task_id,
                            prolog_dir_name, data_dir_name)
    tool_specific_dir = os.path.join(
        '..', '..', learning_task_dir_name, task_id, prolog_dir_name,
        data_dir_name, tool_specific_data_dir)

    # merge all kb files into one
    with open(os.path.join(target_dir, file_name_base+'.b'), 'w') as out:
        # ../../../learningtasks/<task_id>/prolog/data/golem/*.pl
        #                      --> <target_dir>/<file_name_base>.b
        if os.path.isdir(tool_specific_dir):
            for f_name in os.listdir(tool_specific_dir):
                if f_name.endswith('.pl'):
                    subprocess.call(['cat', f_name], cwd=tool_specific_dir,
                                    stdout=out)

        # ../../../learningtasks/<task_id>/prolog/data/*.pl  # merged!
        #                     --> <target_dir>/<file_name_base>.b
        for f_name in os.listdir(data_dir):
            if f_name.endswith('.pl'):
                subprocess.call(['cat', f_name], cwd=data_dir, stdout=out)
        out.flush()

        settings = get_settings(task_id, lp_id, cfg)

        for k, v in settings.items():
            out.write(settings_pattern % (k, v))
            out.write(os.linesep)

    # file_pos --> <target_dir>/<file_name_base>.f
    pos_target_file_path = os.path.join(target_dir, file_name_base+'.f')
    subprocess.call(['cp', file_pos, pos_target_file_path])

    # file_neg --> <target_dir>/<file_name_base>.n
    neg_target_file = os.path.join(target_dir, file_name_base+'.n')
    subprocess.call(['cp', file_neg, neg_target_file])

    # Create the <file_name_base>.r results file
    # (just to avoid the Golem message [Cannot find <file_name_base>.r])
    open(os.path.join(target_dir, file_name_base+'.r'), 'a').close()


def get_and_clean_results(results_dir, f_name_base):
    result_lines = []
    # get all result lines from results file
    with open(os.path.join(results_dir, f_name_base + '.r')) as res:
        for line in res.readlines():
            result_lines.append(line.strip())

    # FIXME: This split-at-').'-and-join-again approach is too weak
    # remove all line breaks and spit again one rule per line
    result_lines = ''.join(result_lines).split(').')
    # add dots (removed in previous line) to rules again
    result_lines = [l + ').' for l in result_lines if l != '']

    # remove all pos examples that could not be generalized
    with open(os.path.join(target_dir, f_name_base + '.f')) as examples:
        for line in examples.readlines():
            line = line.strip()
            if line in result_lines:
                result_lines.remove(line)

    return result_lines


if __name__ == '__main__':
    os.setpgrp()
    argparser = argparse.ArgumentParser()
    argparser.add_argument('config_file')
    args = argparser.parse_args()

    cfg = read_config(args.config_file)
    learning_task_id = cfg['learningtask']
    learning_problem_id = cfg['learningproblem']
    output_file = cfg['filename.output']
    _log.debug('Running learning task %s with learning problem %s' % (
        learning_task_id, learning_problem_id))

    file_name_base = learning_task_id + '_' + learning_problem_id
    # file_name_base = 'data'
    target_dir = cfg['filename.workdir']
    _log.debug('Target dir is %s' % target_dir)

    copy_files_around(learning_task_id, learning_problem_id, target_dir,
                      file_name_base, cfg['filename.neg'], cfg['filename.pos'])

    golem_executable = find_golem()
    _log.debug('Runnig Golem')
    check_call_and_terminate([golem_executable, file_name_base], cwd=target_dir)

    results = get_and_clean_results(target_dir, file_name_base)

    with open(output_file, 'w') as out:
        for line in results:
            out.write(line + os.linesep)

    _log.debug('Golem run finished.')
    _log.debug('Results written to %s' % output_file)
